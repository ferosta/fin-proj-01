# Информационно-аналитическая система "Анализ Новостей" 
    * название проекта в git fin-proj-01 https://github.com/ferosta/fin-proj-01 
    * Работа выполняется в рамках учебного курса "Инженер данных"
        * Итоговая аттестация: вариант проекта №01 https://sprint.1t.ru/user/my-course/186/1097/10447 

# Текущее состояние разработки
    * организован сбор данных из RSS источников;
    * организовано хранение данных сырого слоя (файлы в папках источников);
    * организована инициализирующая и инкрементальная загрузка данных в базу данных;
    * организовано получение обобщающей таблицы с данными из всех источников;
    * организована обобщающая категоризация и разбиение на группы новостей
    
    - все готово для реализации финального слоя витрин,
    - реализация элементов самого слоя витрин в текущей версии разработке пока не предсавлена,
    - над этой частью задания ведется активная работа. 


# Комментарии по заданию

    o   Инициализирующий – загрузка полного слепка данных источника
    * источник через rss возвращает набор данных фиксированной длинны. Реализовано сохранение получаемых данных в виде отдельных файлов и последующаяя загрузка всех сохраненных файлов на этапе инициализации.

    o   Инкрементальный – загрузка дельты данных за прошедшие сутки
    * В cron добавлено выполнение скрипта по сбору данных из источников (сделано немного чаще, чем за сутки). После каждого получепния порции данных, она сразу добавляется в базу данных (Postgress) 

    Организовать правильную структуру хранения данных
        o   Сырой слой данных
        * реализован в форме папок для каждого RSS-источника и хранящихся там файлов с получаемыми в каждом запросе порциями данных. Имена папок - названия источников, имена файлов - таймстампы времени получения данных.

        o   Промежуточный слой
        * база данных Postgress (докер контейнер). Таблицы для каждого источника. Общая объединенная таблица. Таблица с добавленными группами категорий

        o   Слой витрин
        * (== на текущий момент находится на этапе разработки ==)
        планируется реализовать в базе данных Postgres в виде широкой таблицы, получаемой в результате SQL запросов к таблицам промежуточного слоя.




# Описание элементов предлагаемого решения

* Сбор данных из RSS источников
    * список источников храниться в конфигруационном файле 
* Размещение первичных данных в виде файлов по папкам с названиями источников
    * названия папок источников получается из адреса источника - удаляется http, / заменяются на |
    * имена файлов - таймстам момента получения данных
    * формат файлов - json
    * работа с данными ведется с помощью датафреймов Pandas
* Инициализация основного хранилища - база данных Postgres
    * база поднята в докер-контейнере
    * запись в базу ведется средствами Pandas
    * В хранилище записываются все данные ранее, собранные и записанные в подпапки источников
* Инкрементальная загрузка данных
    * Получаем порцию информции из каждого RSS источника
    * записываем ее в виде файла
    * добавляем без дублирования строк в соответствующую SQL таблицу


# Файловая структура проекта
    # config - папка с файлом, где записаны ссылки на источники RSS;
    # data - папка сырого слоя данных. Там хранятся файлы feedов RSS;
    # postgres - папка с конфигурацией docker-compose для Postgres;
    # cron - папка с копией строки инициализации cron регулярного сбора и загрузки данных;
    # prod - папка с рабочими версиями скриптов;
    # category - папка с таблицей обобщенных групп категорий;
    LOG..., DEBUG... - логи выполнения скриптов;
    my_rss_data.ipynb, my_rss_data.py - разрабатываемые версии юпитер ноутбука и спаренного с ним посредством jupytertext скрипта. 

# Задание

<!-- #raw -->
=====================================
Проект № 1.

Анализ публикуемых новостей

Общая задача: создать ETL-процесс формирования витрин данных для анализа публикаций новостей.

Подробное описание задачи:

* Разработать скрипты загрузки данных в 2-х режимах:
    - o   Инициализирующий – загрузка полного слепка данных источника
    - o   Инкрементальный – загрузка дельты данных за прошедшие сутки

* Организовать правильную структуру хранения данных
    - o   Сырой слой данных
    - o   Промежуточный слой
    - o   Слой витрин

* В качестве результата работы программного продукта необходимо написать скрипт, который формирует витрину данных следующего содержания:
    - Суррогатный ключ категории
    - Название категории
    - Общее количество новостей из всех источников по данной категории за все время
    - Количество новостей данной категории для каждого из источников за все время
    - Общее количество новостей из всех источников по данной категории за последние сутки
    - Количество новостей данной категории для каждого из источников за последние сутки
    - Среднее количество публикаций по данной категории в сутки
    - День, в который было сделано максимальное количество публикаций по данной новости
    - Количество публикаций новостей данной категории по дням недели

* Дополнение:

Т.к. в разных источниках названия и разнообразие категорий могут отличаться, вам необходимо привести все к единому виду.

Источники:

https://lenta.ru/rss/
https://www.vedomosti.ru/rss/news
https://tass.ru/rss/v2.xml
<!-- #endraw -->
